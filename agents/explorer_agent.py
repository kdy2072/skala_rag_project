import os
import json
from dotenv import load_dotenv
from typing import List, Dict
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain import hub
from langchain.agents import Tool, AgentExecutor, create_react_agent
from tavily import TavilyClient


BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
FAISS_DIR = os.path.join(BASE_DIR, "faiss_db/unicorns_sementic")
CHECKPOINT_DIR = os.path.join(BASE_DIR, "checkpoint")


class ExplorerAgent:
    def __init__(self,
                 faiss_path=FAISS_DIR,
                 model_name="gpt-4o",
                 embedding_model="nlpai-lab/KURE-v1"):

        load_dotenv()

        # âœ… í™˜ê²½ë³€ìˆ˜ í™•ì¸
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError("âš ï¸ OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        tavily_api_key = os.getenv("TAVILY_API_KEY")
        if not tavily_api_key:
            raise ValueError("âš ï¸ TAVILY_API_KEYê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # âœ… LLM + ì„ë² ë”© ì´ˆê¸°í™”
        self.llm = ChatOpenAI(model=model_name, temperature=0, max_retries=3)
        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model)

        # âœ… VectorDB ë¡œë“œ
        self.vectordb = FAISS.load_local(
            faiss_path,
            self.embeddings,
            allow_dangerous_deserialization=True
        )
        print(f"âœ… Faiss DB ë¡œë“œ ì™„ë£Œ: {faiss_path}")

        # âœ… Tavily Client
        self.web_client = TavilyClient(api_key=tavily_api_key)

    # -----------------------------
    # Tool ì •ì˜
    # -----------------------------
    def rag_search(self, query: str, company_name: str) -> str:
        """FAISS DBì—ì„œ íŠ¹ì • ê¸°ì—…ì˜ ê´€ë ¨ ì²­í¬ë¥¼ ë©”íƒ€ë°ì´í„° í•„í„°ë§ì„ í†µí•´ ê²€ìƒ‰"""
        retriever = self.vectordb.as_retriever(
            search_kwargs={'filter': {'company': company_name}}
        )
        docs = retriever.invoke(query)
        if not docs:
            return "ë¶€ì¡±"
        return "\n\n".join([d.page_content for d in docs])

    def web_search(self, query: str) -> str:
        """Tavilyë¡œ ì›¹ ê²€ìƒ‰"""
        try:
            resp = self.web_client.search(query=query, search_depth="advanced", max_results=3)
            results = [item.get("content", "") for item in resp.get("results", [])]
            return "\n".join(results) if results else "ë¶€ì¡±"
        except Exception as e:
            print(f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ë¶€ì¡±"

    def save_json(self, data: dict, path: str) -> str:
        """ê²°ê³¼ JSON ì €ì¥"""
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        return f"âœ… ì €ì¥ ì™„ë£Œ: {path}"

    # -----------------------------
    # DBì—ì„œ ë¶„ì„í•  íšŒì‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    # -----------------------------
    def get_available_companies(self) -> List[str]:
        """Faiss DBì— ì €ì¥ëœ ëª¨ë“  ê³ ìœ í•œ íšŒì‚¬ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        if not self.vectordb.docstore:
            return []

        unique_companies = set()
        for doc_id in self.vectordb.index_to_docstore_id.values():
            metadata = self.vectordb.docstore.search(doc_id).metadata
            if "company" in metadata:
                unique_companies.add(metadata["company"])

        print(f"ğŸ” ë¶„ì„ ëŒ€ìƒ ê¸°ì—… ëª©ë¡: {list(unique_companies)}")
        return list(unique_companies)

    # -----------------------------
    # ë‹¨ì¼ ê¸°ì—… ë¶„ì„
    # -----------------------------
    def analyze_single_company(self, company_name: str) -> dict:
        print("-" * 50)
        print(f"ğŸš€ '{company_name}' ê¸°ì—… ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        tools = [
            Tool(
                name="RAGSearch",
                func=lambda query: self.rag_search(query=query, company_name=company_name),
                description=f"'{company_name}'ì— ëŒ€í•œ ì§ˆë¬¸ì— FAISS ë²¡í„°DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ëŠ”ë‹¤."
            ),
            Tool(
                name="WebSearch",
                func=self.web_search,
                description="RAGì—ì„œ ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œë‹¤."
            )
        ]

        prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(self.llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)

        final_prompt = f"""
        ë‹¹ì‹ ì€ ì°¨ì„¸ëŒ€ ìœ ë‹ˆì½˜ì„ ì¡°ê¸°ì— ë°œêµ´í•´ë‚´ì•¼ í•˜ëŠ” ê³µê²©ì  íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ë‹¨ìˆœí•œ ê¸°ìˆ  ì„¤ëª…ì´ ì•„ë‹ˆë¼, ì´ ê¸°ì—…ì´ ì‹œì¥ ì§€ë°°ë ¥ì„ í™•ë³´í•  ìˆ˜ ìˆëŠ”ì§€, ìë³¸ íš¨ìœ¨ì„±ì´ ì–¼ë§ˆë‚˜ ë†’ì€ì§€, ê²½ìŸì‚¬ ëŒ€ë¹„ ì ˆëŒ€ì  ìš°ìœ„ê°€ ë¬´ì—‡ì¸ì§€ë¥¼ ì§‘ìš”í•˜ê²Œ íŒŒê³ ë“­ë‹ˆë‹¤.
        íˆ¬ì íŒë‹¨ì— ì§ê²°ë˜ëŠ” í•µì‹¬ ê¸°ìˆ , ì¬ë¬´ì  ì²´ë ¥, íŠ¹í—ˆ ë°©ì–´ë ¥, ì„±ì¥ ë¦¬ìŠ¤í¬ë¥¼ ëƒ‰ì •í•˜ê²Œ ê²€ì¦í•˜ê³ , íˆ¬ììì˜ ì‹œê°ì—ì„œ ê¸°íšŒì™€ ìœ„í—˜ì„ ë™ì‹œì— ë“œëŸ¬ë‚´ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì„ë¬´ì…ë‹ˆë‹¤.
                
        ë¶„ì„ ëŒ€ìƒ ê¸°ì—…ì€ ì „ë¶€ í•œêµ­ê³„ ê¸°ì—… '{company_name}'ì…ë‹ˆë‹¤.

        ì•„ë˜ 5ê°€ì§€ ì£¼ì œì— ëŒ€í•´ ë°˜ë“œì‹œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  JSONìœ¼ë¡œ ì •ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤:
        - owner: ê¸°ì—… ì†Œìœ ì ì—…ë ¥ ì‚¬í•­
        - core_tech: ê¸°ì—…ì˜ í•µì‹¬ ê¸°ìˆ 
        - pros: ê¸°ì—…ì˜ ê°•ì 
        - patents: ê¸°ì—…ì˜ ë³´ìœ  íŠ¹í—ˆ ì •ë³´
        - investments: ê¸°ì—…ì˜ ê¸° íˆ¬ì ì •ë³´

        ê·œì¹™:
        1. ê° í•­ëª©ë§ˆë‹¤ ë¨¼ì € RAGSearchë¥¼ ì‚¬ìš©í•´ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        2. RAGSearch ê²°ê³¼ê°€ 'ë¶€ì¡±'ì´ë¼ë©´ WebSearchë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        3. ë‘ ë°©ë²• ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ 'ì •ë³´ í™•ì¸ ë¶ˆê°€'ì´ë¼ê³  ê¸°ë¡í•©ë‹ˆë‹¤.
        4. ìµœì¢… ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ë©°,
           ì•„ë˜ ì˜ˆì‹œ ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
        5. ë‚´ìš©ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œë§Œ ì‘ì„±í•©ë‹ˆë‹¤.

        ì¶œë ¥ ì˜ˆì‹œ:
        ```json
            {{
                "owner": "...",
                "core_tech": "...",
                "pros": "...",
                "patents": "...",
                "investments": "..."
            }}
        ```
        """

        try:
            response = agent_executor.invoke({"input": final_prompt})
            raw_output = response.get("output", "") if isinstance(response, dict) else str(response)
            cleaned = raw_output.strip().replace("```json", "").replace("```", "")

            try:
                parsed = json.loads(cleaned)
            except Exception:
                parsed = {
                    "core_tech": "ì—†ìŒ",
                    "pros_cons": {"pros": "ì—†ìŒ", "cons": "ì—†ìŒ"},
                    "patents": "ì—†ìŒ",
                    "investments": "ì—†ìŒ",
                    "raw_output": cleaned
                }

            return parsed

        except Exception as e:
            return {"company": company_name, "error": str(e)}

    # -----------------------------
    # ì „ì²´ ë¶„ì„ ì‹¤í–‰
    # -----------------------------
    def run_full_analysis(self) -> List[Dict]:
        print("ğŸš€ run_full_analysis() ì‹œì‘")

        companies_to_analyze = self.get_available_companies()
        print(f"ğŸ“ get_available_companies ê²°ê³¼: {companies_to_analyze}")

        all_results = []

        if not companies_to_analyze:
            print("âš ï¸ ë¶„ì„í•  ê¸°ì—…ì´ VectorDBì— ì—†ìŠµë‹ˆë‹¤.")
            return []

        for idx, company in enumerate(companies_to_analyze, start=1):
            print(f"\n[{idx}/{len(companies_to_analyze)}] í˜„ì¬ ê¸°ì—… ë¶„ì„ ì¤‘: {company}")

            result_json = self.analyze_single_company(company)
            print(f"ğŸ” analyze_single_company ë°˜í™˜ íƒ€ì…: {type(result_json)}")
            print(f"ğŸ“¦ analyze_single_company ê²°ê³¼ ì¼ë¶€: {str(result_json)[:200]}")

            # ğŸš¨ dict ë³´ì¥
            if not isinstance(result_json, dict):
                print("âš ï¸ ë°˜í™˜ê°’ì´ dictê°€ ì•„ë‹˜ â†’ dictë¡œ ë˜í•‘")
                result_json = {"error": "Invalid return type", "raw": str(result_json)}

            result_json["company_name"] = company
            all_results.append(result_json)
            print(f"âœ… {company} ë¶„ì„ ì™„ë£Œ, ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë¨")

        print("\n\nğŸ‰ ëª¨ë“  ê¸°ì—… ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì¢… ê²°ê³¼ ê°œìˆ˜: {len(all_results)}")
        return all_results



# --- ì—¬ê¸°ê°€ ì‹¤ì œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤ ---
if __name__ == "__main__":
    # 1. ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    agent = ExplorerAgent()
    
    # 2. ì „ì²´ ë¶„ì„ ì‹¤í–‰
    final_results_list = agent.run_full_analysis()
    
    # 3. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n--- ìµœì¢… ë¶„ì„ ê²°ê³¼ (List[JSON]) ---")
    # pretty printing
    # ì €ì¥ ê²½ë¡œ

    output_path = os.path.join(CHECKPOINT_DIR, "01_company_desc_semantic.json")


    # ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # JSON ì €ì¥
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(final_results_list, f, indent=4, ensure_ascii=False)

    print(json.dumps(final_results_list, indent=4, ensure_ascii=False))