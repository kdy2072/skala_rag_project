import json
import os
from typing import Dict, List, Annotated, Sequence, Literal, Union
from dotenv import load_dotenv
from pydantic import BaseModel, Field

from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from tavily import TavilyClient
import requests
import xml.etree.ElementTree as ET

from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from InvestmentState import InvestmentState
load_dotenv()

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
FAISS_DIR = os.path.join(BASE_DIR, "faiss_db/unicorns_sementic")
CHECKPOINT_DIR = os.path.join(BASE_DIR, "checkpoint")


class TechAnalysisState(BaseModel):
    """ì§„ì§œ Agent ìƒíƒœ"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    company_name: str = ""
    core_tech: str = ""
    patents: str = ""
    investments: str = ""
    pros: str = ""
    owner: str = ""
    
    # ìµœì¢… ì¶œë ¥
    tech_summary: str = ""
    strengths_and_weaknesses: Union[str, Dict] = ""   # âœ… dictë„ í—ˆìš©
    differentiation_points: Union[str, List[str]] = "" # âœ… listë„ í—ˆìš©
    technical_risks: Union[str, List[str]] = "" 
    patents_and_papers: List[str] = []
    
    confidence_score: float = 0.0


class RelevanceGrade(BaseModel):
    """ê´€ë ¨ì„± í‰ê°€"""
    binary_score: str = Field(description="'yes' if relevant, 'no' if not")


class TechSummaryAgent:
    """ì§„ì§œ Agent ê¸°ë°˜ ê¸°ìˆ  ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self, faiss_path=FAISS_DIR, embedding_model="nlpai-lab/KURE-v1"):
        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model)
        self.vectordb = FAISS.load_local(
            folder_path=faiss_path,
            embeddings=self.embeddings,
            allow_dangerous_deserialization=True
        )
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        self.web_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
        
        # ì „ì—­ ë³€ìˆ˜ë¡œ ì €ì¥ (tool í•¨ìˆ˜ì—ì„œ ì ‘ê·¼)
        global _vectordb, _web_client, _kipris_tool
        _vectordb = self.vectordb
        _web_client = self.web_client
        _kipris_tool = KIPRISPatentTool()
        
        print(f"âœ… ì§„ì§œ Agent ì´ˆê¸°í™” ì™„ë£Œ")
        
        self.graph = self._build_graph()
    
    def _build_graph(self):
        """ì§„ì§œ Agent íŒ¨í„´ ê·¸ë˜í”„"""
        workflow = StateGraph(TechAnalysisState)
        
        # ë„êµ¬ ì •ì˜
        tools = [rag_search_tool, web_search_tool, kipris_search_tool]
        
        # ToolNode ìƒì„± (ì§„ì§œ Agentì˜ í•µì‹¬)
        tool_node = ToolNode(tools)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("tools", tool_node)  # ToolNode ì‚¬ìš©
        workflow.add_node("grade_documents", self._grade_documents)
        workflow.add_node("rewrite", self._rewrite_query)
        workflow.add_node("generate", self._generate_summary)
        
        # ì‹œì‘
        workflow.add_edge(START, "agent")
        
        # Agentê°€ ë„êµ¬ ì„ íƒ (tools_condition ì‚¬ìš©)
        workflow.add_conditional_edges(
            "agent",
            tools_condition,  # ì§„ì§œ Agentì˜ í•µì‹¬
            {
                "tools": "tools",  # Agentê°€ ë„êµ¬ í˜¸ì¶œ
                END: END
            }
        )
        
        # ë„êµ¬ ì‹¤í–‰ í›„ ê´€ë ¨ì„± í‰ê°€
        workflow.add_edge("tools", "grade_documents")
        
        # ê´€ë ¨ì„± í‰ê°€ í›„ ë¶„ê¸°
        workflow.add_conditional_edges(
            "grade_documents",
            self._decide_next_step,
            {
                "rewrite": "rewrite",
                "generate": "generate"
            }
        )
        
        # ì¿¼ë¦¬ ì¬ì‘ì„± í›„ ë‹¤ì‹œ Agentë¡œ
        workflow.add_edge("rewrite", "agent")
        
        # ìµœì¢… ìš”ì•½ í›„ ì¢…ë£Œ
        workflow.add_edge("generate", END)
        
        return workflow.compile()
    
    def _agent_node(self, state: TechAnalysisState) -> TechAnalysisState:
        """ì§„ì§œ Agent - ë„êµ¬ë¥¼ bindí•˜ê³  ìë™ ì„ íƒ"""
        print(f"\nğŸ¤– Agent ì‹¤í–‰ ì¤‘...")
        
        # MVP: ê°„ë‹¨í•œ ë¬´í•œë£¨í”„ ë°©ì§€
        if len(state.messages) > 6:
            return {"messages": [HumanMessage(content="ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")]}
        
        tools = [rag_search_tool, web_search_tool, kipris_search_tool]
        model_with_tools = self.llm.bind_tools(tools)
        
        system_msg = f"""ê¸°ìˆ  ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ {state.company_name}ì˜ {state.core_tech} ê¸°ìˆ ì„ ë¶„ì„í•˜ì„¸ìš”.

2-3íšŒ ë„êµ¬ ì‚¬ìš© í›„ "ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ"ë¼ê³  ë‹µí•˜ì„¸ìš”."""
        
        messages = [HumanMessage(content=system_msg)] + list(state.messages[1:])
        response = model_with_tools.invoke(messages)
        
        print(f"ğŸ’­ Agent ì‘ë‹µ: {response.content if response.content else 'ë„êµ¬ í˜¸ì¶œ'}")
        
        return {"messages": [response]}
    
    def _grade_documents(self, state: TechAnalysisState) -> TechAnalysisState:
        """LLMì´ ì •ë³´ ì¶©ë¶„ì„± í‰ê°€"""
        print("ğŸ” ì •ë³´ ì¶©ë¶„ì„± í‰ê°€ ì¤‘...")
        
        # ë§ˆì§€ë§‰ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì¶”ì¶œ
        last_message = state.messages[-1]
        retrieved_docs = last_message.content if hasattr(last_message, 'content') else ""
        
        llm_with_tool = self.llm.with_structured_output(RelevanceGrade)
        
        prompt = PromptTemplate(
            template="""ë‹¤ìŒ ì •ë³´ê°€ "{company}"ì˜ "{tech}" ê¸°ìˆ  ë¶„ì„ì— ì¶©ë¶„í•œì§€ í‰ê°€í•˜ì„¸ìš”:

ê²€ìƒ‰ ê²°ê³¼:
{docs}

í‰ê°€ ê¸°ì¤€:
1. ê¸°ìˆ ì˜ ì‘ë™ ì›ë¦¬ê°€ ì„¤ëª…ë˜ì–´ ìˆëŠ”ê°€?
2. ê²½ìŸ ê¸°ìˆ ê³¼ì˜ ì°¨ë³„ì ì´ ìˆëŠ”ê°€?
3. íŠ¹í—ˆë‚˜ ì—°êµ¬ ì„±ê³¼ê°€ ì–¸ê¸‰ë˜ëŠ”ê°€?

ì¶©ë¶„í•˜ë©´ 'yes', ë¶€ì¡±í•˜ë©´ 'no'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.""",
            input_variables=["company", "tech", "docs"]
        )
        
        chain = prompt | llm_with_tool
        result = chain.invoke({
            "company": state.company_name,
            "tech": state.core_tech,
            "docs": str(retrieved_docs)[:1000]
        })
        
        print(f"ğŸ“Š í‰ê°€ ê²°ê³¼: {result.binary_score}")
        
        state.confidence_score = 80 if result.binary_score == "yes" else 40
        
        return state
    
    def _decide_next_step(self, state: TechAnalysisState) -> Literal["rewrite", "generate"]:
        """ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""
        if state.confidence_score >= 70:
            print("âœ… ì¶©ë¶„í•œ ì •ë³´ ìˆ˜ì§‘ë¨")
            return "generate"
        else:
            print("ğŸ”„ ì •ë³´ ë¶€ì¡±, ì¿¼ë¦¬ ì¬ì‘ì„±")
            return "rewrite"
    
    def _rewrite_query(self, state: TechAnalysisState) -> TechAnalysisState:
        """LLMì´ ê²€ìƒ‰ ì¿¼ë¦¬ ê°œì„ """
        print(f"âœï¸ ê²€ìƒ‰ ì¿¼ë¦¬ ì¬ì‘ì„± ì¤‘...")
        
        prompt = f"""ë‹¤ìŒ ê¸°ìˆ  ë¶„ì„ì„ ìœ„í•´ ë” ë‚˜ì€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”:

íšŒì‚¬: {state.company_name}
ê¸°ìˆ : {state.core_tech}

í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. 
ê¸°ìˆ ì˜ í•µì‹¬ ì›ë¦¬, ê²½ìŸ ê¸°ìˆ ê³¼ì˜ ì°¨ë³„ì , íŠ¹í—ˆ ë° ì—°êµ¬ ì„±ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ê°œì„ ëœ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì œì•ˆí•˜ì„¸ìš”.

ê°œì„ ëœ ê²€ìƒ‰ ì¿¼ë¦¬:"""
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        improved_query = response.content.strip()
        
        print(f"ğŸ’¡ ê°œì„ ëœ ì¿¼ë¦¬: {improved_query}")
        
        return {"messages": [HumanMessage(content=improved_query)]}
    
    def _generate_summary(self, state: TechAnalysisState) -> TechAnalysisState:
        """ìµœì¢… ìš”ì•½ ìƒì„±"""
        print("ğŸ“ ìµœì¢… ìš”ì•½ ìƒì„± ì¤‘...")
        
        # ëª¨ë“  ë©”ì‹œì§€ì—ì„œ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì¶”ì¶œ
        all_evidence = []
        for msg in state.messages:
            if hasattr(msg, 'content') and msg.content:
                all_evidence.append(str(msg.content))
        
        combined_evidence = "\n\n".join(all_evidence[-5:])  # ìµœê·¼ 5ê°œ
        
        prompt = PromptTemplate(
            template="""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ì ê´€ì ì˜ ê¸°ìˆ  ìš”ì•½ì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”:

íšŒì‚¬: {company}
í•µì‹¬ ê¸°ìˆ : {tech}
ê°•ì : {pros}

ìˆ˜ì§‘ëœ ì •ë³´:
{evidence}

JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
{{
    "tech_summary": "ê¸°ìˆ  ìš”ì•½ (300-500ì)",
    "strengths_and_weaknesses": "ê°•ì /ì•½ì  ë¶„ì„",
    "differentiation_points": "ì°¨ë³„ì ",
    "technical_risks": "ê¸°ìˆ  ë¦¬ìŠ¤í¬",
    "patents_and_papers": ["íŠ¹í—ˆ1", "ë…¼ë¬¸1"]
}}""",
            input_variables=["company", "tech", "pros", "evidence"]
        )
        
        chain = prompt | self.llm | StrOutputParser()
        summary = chain.invoke({
            "company": state.company_name,
            "tech": state.core_tech,
            "pros": state.pros,
            "evidence": combined_evidence[:2000]
        })
        
        try:
            cleaned = summary.strip().replace('```json', '').replace('```', '')
            parsed = json.loads(cleaned)
            
            state.tech_summary = parsed.get("tech_summary", "")
            state.strengths_and_weaknesses = parsed.get("strengths_and_weaknesses", "")
            state.differentiation_points = parsed.get("differentiation_points", "")
            state.technical_risks = parsed.get("technical_risks", "")
            state.patents_and_papers = parsed.get("patents_and_papers", [])
            
            print("âœ… ìš”ì•½ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            state.tech_summary = f"{state.company_name}ì˜ {state.core_tech} ê¸°ìˆ  ë¶„ì„"
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return state


    def run(self, state: InvestmentState) -> InvestmentState:
        print(f"\nğŸš€ TechSummaryAgent ì‹œì‘: {state.company_name} - {state.core_tech}")

        initial_state = TechAnalysisState(
            messages=[HumanMessage(content=f"ê¸°ìˆ  ë¶„ì„ ì‹œì‘: {state.company_name} - {state.core_tech}")],
            company_name=state.company_name,
            core_tech=state.core_tech,
            patents=state.patents,
            investments="",
            pros=state.pros,
            owner=state.owner
        )

        # graph.invoke â†’ dict ë°˜í™˜
        final_state_dict = self.graph.invoke(initial_state, {"recursion_limit": 15})

        # dict â†’ Pydantic ëª¨ë¸ ë³€í™˜
        final_state = TechAnalysisState(**final_state_dict)

        # âœ… ê²°ê³¼ë¥¼ InvestmentStateì— ë°˜ì˜
        state.tech_summary = final_state.tech_summary
        state.strengths_and_weaknesses = final_state.strengths_and_weaknesses
        state.differentiation_points = final_state.differentiation_points
        state.technical_risks = final_state.technical_risks
        state.patents_and_papers = final_state.patents_and_papers
        state.confidence_score = final_state.confidence_score

        return state
# ============================================
# ë„êµ¬ ì •ì˜ (ì§„ì§œ Agentì˜ í•µì‹¬)
# ============================================

@tool
def rag_search_tool(query: str) -> str:
    """
    ë‚´ë¶€ ë¬¸ì„œì—ì„œ ê¸°ìˆ  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  ê¸°ìˆ  í‚¤ì›Œë“œ (ì˜ˆ: "AI ê¸°ë°˜ ì‹ ì•½ ê°œë°œ ê¸°ìˆ ")
    
    Returns:
        ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©
    """
    print(f"ğŸ“š RAG ê²€ìƒ‰: {query}")
    
    try:
        retriever = _vectordb.as_retriever(search_kwargs={'k': 5})
        docs = retriever.invoke(query)
        
        if docs:
            result = "\n\n".join([doc.page_content for doc in docs])
            print(f"âœ… {len(docs)}ê°œ ë¬¸ì„œ ë°œê²¬")
            return result
        else:
            print("âš ï¸ ê²°ê³¼ ì—†ìŒ")
            return "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


@tool
def web_search_tool(query: str) -> str:
    """
    ì›¹ì—ì„œ ìµœì‹  ê¸°ìˆ  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  ê¸°ìˆ  í‚¤ì›Œë“œ (ì˜ˆ: "Qgenetics QG3030 ì‹ ì•½ ê°œë°œ")
    
    Returns:
        ê²€ìƒ‰ëœ ì›¹ í˜ì´ì§€ ë‚´ìš©
    """
    print(f"ğŸŒ ì›¹ ê²€ìƒ‰: {query}")
    
    try:
        response = _web_client.search(query=query, search_depth="advanced", max_results=5)
        results = response.get("results", [])
        
        if results:
            content = "\n\n".join([
                f"ì œëª©: {r.get('title', '')}\në‚´ìš©: {r.get('content', '')[:300]}"
                for r in results
            ])
            print(f"âœ… {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
            return content
        else:
            print("âš ï¸ ê²°ê³¼ ì—†ìŒ")
            return "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


class KIPRISPatentTool:
    def __init__(self):
        self.service_key = os.getenv("KIPRIS_SERVICE_KEY")
        self.base_url = "http://plus.kipris.or.kr/kipo-api/kipi/patUtiModInfoSearchService/getAdvancedSearch"
    
    def search_patents(self, keyword: str, max_results: int = 5) -> List[Dict]:
        try:
            if not self.service_key:
                return [{'title': f'{keyword} ê´€ë ¨ íŠ¹í—ˆ', 'applicant': 'ê¸°ìˆ ê°œë°œíšŒì‚¬'}]
            
            params = {
                'inventionTitle': keyword,
                'patent': 'true',
                'numOfRows': max_results,
                'ServiceKey': self.service_key
            }
            
            response = requests.get(self.base_url, params=params, timeout=10)
            if response.status_code != 200:
                return []
            
            root = ET.fromstring(response.content)
            patents = []
            
            for item in root.findall('.//item'):
                patent = {
                    'title': self._get_text(item, 'inventionTitle'),
                    'applicant': self._get_text(item, 'applicantName'),
                    'register_number': self._get_text(item, 'registerNumber')
                }
                patents.append(patent)
            
            return patents
        except:
            return []
    
    def _get_text(self, element, tag):
        found = element.find(tag)
        return found.text if found is not None and found.text else ""


@tool
def kipris_search_tool(query: str) -> str:
    """
    KIPRISì—ì„œ íŠ¹í—ˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  íŠ¹í—ˆ í‚¤ì›Œë“œ (ì˜ˆ: "QG3030 ì‹ ì•½")
    
    Returns:
        ê²€ìƒ‰ëœ íŠ¹í—ˆ ì •ë³´
    """
    print(f"ğŸ›ï¸ KIPRIS íŠ¹í—ˆ ê²€ìƒ‰: {query}")
    
    try:
        patents = _kipris_tool.search_patents(query, 5)
        
        if patents:
            content = "\n\n".join([
                f"íŠ¹í—ˆëª…: {p.get('title', '')}\nì¶œì›ì¸: {p.get('applicant', '')}\në“±ë¡ë²ˆí˜¸: {p.get('register_number', '')}"
                for p in patents
            ])
            print(f"âœ… {len(patents)}ê°œ íŠ¹í—ˆ ë°œê²¬")
            return content
        else:
            print("âš ï¸ íŠ¹í—ˆ ì—†ìŒ")
            return "íŠ¹í—ˆ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return f"íŠ¹í—ˆ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


if __name__ == "__main__":
    checkpoint_path = os.path.join(CHECKPOINT_DIR, "01_company_desc_semantic.json")
    
    if os.path.exists(checkpoint_path):
        with open(checkpoint_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        agent = TechSummaryAgent()
        
        for company_data in data[:1]:  # í…ŒìŠ¤íŠ¸ìš© 1ê°œë§Œ
            result = agent.run(company_data)
            print(f"\nê²°ê³¼:\n{json.dumps(result, indent=2, ensure_ascii=False)}")
    else:
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {checkpoint_path}")
