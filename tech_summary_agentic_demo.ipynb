{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– Agentic ê¸°ìˆ  ìš”ì•½ ì—ì´ì „íŠ¸ ì‹¤ìŠµ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì›¹ê²€ìƒ‰ ê¸°ë°˜ Agentic ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš”ì‹œ)\n",
    "# !pip install langchain-openai langchain-community tavily-python python-dotenv\n",
    "# !pip install matplotlib networkx plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "# LangChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agentic ì›Œí¬í”Œë¡œìš° í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ í´ë˜ìŠ¤\n",
    "class TechAnalysisState:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        return getattr(self, key, default)\n",
    "    \n",
    "    def update(self, data):\n",
    "        for key, value in data.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "print(\"âœ… ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ìˆ  ì‹¤ì¡´ì„± ê²€ì¦ ë„êµ¬\n",
    "class TechExistenceValidatorTool:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "        try:\n",
    "            self.web_search = TavilySearchResults(max_results=3)\n",
    "            self.web_enabled = True\n",
    "        except:\n",
    "            self.web_enabled = False\n",
    "            print(\"âš ï¸ ì›¹ ê²€ìƒ‰ ë¹„í™œì„±í™” (Tavily API í‚¤ ì—†ìŒ)\")\n",
    "        \n",
    "    def run(self, state: TechAnalysisState) -> TechAnalysisState:\n",
    "        print(f\"ğŸ” [1ë‹¨ê³„] ê¸°ìˆ  ì‹¤ì¡´ì„± ê²€ì¦: {state.get('company_name', '')}\")\n",
    "        \n",
    "        company_name = state.get(\"company_name\", \"\")\n",
    "        core_tech = state.get(\"core_tech\", \"\")\n",
    "        \n",
    "        # ì›¹ ê²€ìƒ‰ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "        web_context = \"ì›¹ ê²€ìƒ‰ ë¹„í™œì„±í™”\"\n",
    "        if self.web_enabled:\n",
    "            try:\n",
    "                web_query = f'\"{company_name}\" \"{core_tech}\" technology'\n",
    "                web_results = self.web_search.run(web_query)\n",
    "                web_context = \"\\n\".join([str(result)[:100] for result in web_results])\n",
    "                print(\"  âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"  âš ï¸ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "                web_context = \"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨\"\n",
    "        \n",
    "        # ê¸°ë³¸ì ìœ¼ë¡œ ì •ì œëœ ë°ì´í„°ëŠ” ì‹ ë¢°\n",
    "        confidence = 85 if company_name and core_tech else 50\n",
    "        tech_exists = confidence >= 70\n",
    "        \n",
    "        state.tech_exists = tech_exists\n",
    "        state.tech_cache = {\n",
    "            \"confidence\": confidence,\n",
    "            \"web_evidence\": web_context[:200],\n",
    "            \"validation_method\": \"ì •ì œëœ ë°ì´í„° + ì›¹ê²€ìƒ‰\"\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ… ê²€ì¦ ì™„ë£Œ: {tech_exists} (í™•ì‹ ë„: {confidence}%)\")\n",
    "        return state\n",
    "\n",
    "print(\"âœ… ê¸°ìˆ  ê²€ì¦ ë„êµ¬ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•µì‹¬ ê¸°ìˆ  ë¶„ì„ ë„êµ¬\n",
    "class CoreTechAnalyzerTool:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "        try:\n",
    "            self.web_search = TavilySearchResults(max_results=2)\n",
    "            self.web_enabled = True\n",
    "        except:\n",
    "            self.web_enabled = False\n",
    "        \n",
    "    def run(self, state: TechAnalysisState) -> TechAnalysisState:\n",
    "        print(f\"ğŸ”¬ [2ë‹¨ê³„] í•µì‹¬ ê¸°ìˆ  ë¶„ì„\")\n",
    "        \n",
    "        company_name = state.get(\"company_name\", \"\")\n",
    "        core_tech = state.get(\"core_tech\", \"\")\n",
    "        pros = state.get(\"pros\", \"\")\n",
    "        \n",
    "        # ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ê¸°ìˆ  ì •ë³´ ë³´ê°•\n",
    "        web_tech_info = \"ì›¹ ê²€ìƒ‰ ë¹„í™œì„±í™”\"\n",
    "        if self.web_enabled:\n",
    "            try:\n",
    "                tech_query = f'\"{core_tech}\" how it works technology'\n",
    "                web_results = self.web_search.run(tech_query)\n",
    "                web_tech_info = \"\\n\".join([str(result)[:100] for result in web_results])\n",
    "                print(\"  âœ… ê¸°ìˆ  ì •ë³´ ì›¹ ê²€ìƒ‰ ì™„ë£Œ\")\n",
    "            except:\n",
    "                print(\"  âš ï¸ ê¸°ìˆ  ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨\")\n",
    "        \n",
    "        # ê¸°ìˆ  ë¶„ì„ (ê°„ì†Œí™”)\n",
    "        if not hasattr(state, 'tech_cache'):\n",
    "            state.tech_cache = {}\n",
    "        \n",
    "        state.tech_cache.update({\n",
    "            \"mechanism\": f\"{core_tech}ì˜ í•µì‹¬ ì‘ë™ ì›ë¦¬ ë° ë©”ì»¤ë‹ˆì¦˜\",\n",
    "            \"applications\": f\"{company_name}ì˜ ê¸°ìˆ  ì ìš© ë¶„ì•¼ ë° í™œìš© ê°€ëŠ¥ì„±\",\n",
    "            \"advantages\": f\"{core_tech}ì˜ ì£¼ìš” ê¸°ìˆ ì  ì¥ì : {pros[:100]}\",\n",
    "            \"web_research\": web_tech_info[:150]\n",
    "        })\n",
    "        \n",
    "        print(\"  âœ… ê¸°ìˆ  ë¶„ì„ ì™„ë£Œ\")\n",
    "        return state\n",
    "\n",
    "print(\"âœ… ê¸°ìˆ  ë¶„ì„ ë„êµ¬ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IP ê²€ì¦ ë„êµ¬\n",
    "class IP_ResearchValidatorTool:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "        try:\n",
    "            self.web_search = TavilySearchResults(max_results=2)\n",
    "            self.web_enabled = True\n",
    "        except:\n",
    "            self.web_enabled = False\n",
    "        \n",
    "    def run(self, state: TechAnalysisState) -> TechAnalysisState:\n",
    "        print(f\"ğŸ“‹ [3ë‹¨ê³„] IP ê²€ì¦\")\n",
    "        \n",
    "        company_name = state.get(\"company_name\", \"\")\n",
    "        patents_info = state.get(\"patents\", \"\")\n",
    "        \n",
    "        # ì›¹ ê²€ìƒ‰ìœ¼ë¡œ íŠ¹í—ˆ ì •ë³´ êµì°¨ ê²€ì¦\n",
    "        web_patent_info = \"ì›¹ ê²€ìƒ‰ ë¹„í™œì„±í™”\"\n",
    "        if self.web_enabled:\n",
    "            try:\n",
    "                patent_query = f'\"{company_name}\" patents'\n",
    "                web_results = self.web_search.run(patent_query)\n",
    "                web_patent_info = \"\\n\".join([str(result)[:100] for result in web_results])\n",
    "                print(\"  âœ… íŠ¹í—ˆ ì •ë³´ ì›¹ ê²€ìƒ‰ ì™„ë£Œ\")\n",
    "            except:\n",
    "                print(\"  âš ï¸ íŠ¹í—ˆ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨\")\n",
    "        \n",
    "        # íŠ¹í—ˆ ë¶„ì„ (ê°„ì†Œí™”)\n",
    "        patent_count = len([x for x in patents_info.split() if x.isdigit()]) if patents_info else 0\n",
    "        \n",
    "        state.ip_cache = {\n",
    "            \"patent_analysis\": {\n",
    "                \"patent_count\": patent_count,\n",
    "                \"main_fields\": [\"AI/ML\", \"í—¬ìŠ¤ì¼€ì–´\"],\n",
    "                \"technical_value\": \"ì¤‘ê°„-ë†’ìŒ ìˆ˜ì¤€ì˜ ê¸°ìˆ ì  ê°€ì¹˜\",\n",
    "                \"competitive_strength\": \"íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì¶• ì¤‘\"\n",
    "            },\n",
    "            \"web_verification\": web_patent_info[:200],\n",
    "            \"significance\": \"high\" if patent_count > 10 else \"medium\"\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ… IP ê²€ì¦ ì™„ë£Œ (íŠ¹í—ˆ {patent_count}ê±´)\")\n",
    "        return state\n",
    "\n",
    "print(\"âœ… IP ê²€ì¦ ë„êµ¬ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ìŸ ë¶„ì„ ì—ì´ì „íŠ¸\n",
    "class CompetitiveLandscapeAgent:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "        try:\n",
    "            self.web_search = TavilySearchResults(max_results=3)\n",
    "            self.web_enabled = True\n",
    "        except:\n",
    "            self.web_enabled = False\n",
    "        \n",
    "    def run(self, state: TechAnalysisState) -> TechAnalysisState:\n",
    "        print(f\"ğŸ† [4ë‹¨ê³„] ê²½ìŸ ë¶„ì„\")\n",
    "        \n",
    "        company_name = state.get(\"company_name\", \"\")\n",
    "        core_tech = state.get(\"core_tech\", \"\")\n",
    "        \n",
    "        # ê²½ìŸì‚¬ ê²€ìƒ‰\n",
    "        competitors_info = \"ì›¹ ê²€ìƒ‰ ë¹„í™œì„±í™”\"\n",
    "        if self.web_enabled:\n",
    "            try:\n",
    "                comp_query = f'\"{core_tech}\" competitors market'\n",
    "                web_results = self.web_search.run(comp_query)\n",
    "                competitors_info = \"\\n\".join([str(result)[:100] for result in web_results])\n",
    "                print(\"  âœ… ê²½ìŸì‚¬ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ\")\n",
    "            except:\n",
    "                print(\"  âš ï¸ ê²½ìŸì‚¬ ê²€ìƒ‰ ì‹¤íŒ¨\")\n",
    "        \n",
    "        # ê²½ìŸ ë¶„ì„ ê²°ê³¼\n",
    "        state.competition_cache = {\n",
    "            \"competitors\": [\"ê²½ìŸì‚¬ A\", \"ê²½ìŸì‚¬ B\", \"ê²½ìŸì‚¬ C\"],\n",
    "            \"differentiation\": f\"{core_tech} ë¶„ì•¼ì—ì„œì˜ ë…íŠ¹í•œ ê¸°ìˆ ì  ì ‘ê·¼ë²•\",\n",
    "            \"advantages\": f\"{company_name}ì˜ ê¸°ìˆ ì  ê²½ìŸ ìš°ìœ„\",\n",
    "            \"positioning\": \"ì‹œì¥ì—ì„œì˜ ì°¨ë³„í™”ëœ í¬ì§€ì…”ë‹\",\n",
    "            \"web_research\": competitors_info[:200]\n",
    "        }\n",
    "        \n",
    "        print(\"  âœ… ê²½ìŸ ë¶„ì„ ì™„ë£Œ\")\n",
    "        return state\n",
    "\n",
    "print(\"âœ… ê²½ìŸ ë¶„ì„ ë„êµ¬ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë©”ì¸ Agentic ì—ì´ì „íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TechSummaryAgent:\n",
    "    def __init__(self):\n",
    "        self.tech_validator = TechExistenceValidatorTool()\n",
    "        self.core_analyzer = CoreTechAnalyzerTool()\n",
    "        self.ip_validator = IP_ResearchValidatorTool()\n",
    "        self.competitive_agent = CompetitiveLandscapeAgent()\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "        \n",
    "        # ì‹¤í–‰ ë¡œê·¸\n",
    "        self.execution_log = []\n",
    "        \n",
    "    def run(self, input_json: dict) -> dict:\n",
    "        print(\"ğŸš€ Agentic TechSummaryAgent ì‹œì‘\")\n",
    "        print(f\"ğŸ“¥ ë¶„ì„ ëŒ€ìƒ: {input_json.get('company_name', '')}\")\n",
    "        \n",
    "        # ìƒíƒœ ì´ˆê¸°í™”\n",
    "        state = TechAnalysisState(\n",
    "            company_name=input_json.get(\"company_name\", \"\"),\n",
    "            core_tech=input_json.get(\"core_tech\", \"\"),\n",
    "            patents=input_json.get(\"patents\", \"\"),\n",
    "            investments=input_json.get(\"investments\", \"\"),\n",
    "            pros=input_json.get(\"pros\", \"\"),\n",
    "            owner=input_json.get(\"owner\", \"\"),\n",
    "            tech_exists=False\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Agentic ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "            self.execution_log = []\n",
    "            \n",
    "            # 1ë‹¨ê³„: ê¸°ìˆ  ì‹¤ì¡´ì„± ê²€ì¦\n",
    "            self.execution_log.append(\"ê¸°ìˆ  ì‹¤ì¡´ì„± ê²€ì¦ ì‹œì‘\")\n",
    "            state = self.tech_validator.run(state)\n",
    "            self.execution_log.append(f\"ê²€ì¦ ê²°ê³¼: {state.get('tech_exists', False)}\")\n",
    "            \n",
    "            # ì¡°ê±´ë¶€ ë¶„ê¸°\n",
    "            if state.get(\"tech_exists\", False):\n",
    "                self.execution_log.append(\"ìƒì„¸ ë¶„ì„ ê²½ë¡œ ì„ íƒ\")\n",
    "                \n",
    "                # 2ë‹¨ê³„: í•µì‹¬ ê¸°ìˆ  ë¶„ì„\n",
    "                self.execution_log.append(\"í•µì‹¬ ê¸°ìˆ  ë¶„ì„ ì‹œì‘\")\n",
    "                state = self.core_analyzer.run(state)\n",
    "                \n",
    "                # 3ë‹¨ê³„: IP ê²€ì¦\n",
    "                self.execution_log.append(\"IP ê²€ì¦ ì‹œì‘\")\n",
    "                state = self.ip_validator.run(state)\n",
    "                \n",
    "                # 4ë‹¨ê³„: ê²½ìŸ ë¶„ì„\n",
    "                self.execution_log.append(\"ê²½ìŸ ë¶„ì„ ì‹œì‘\")\n",
    "                state = self.competitive_agent.run(state)\n",
    "                \n",
    "                # 5ë‹¨ê³„: ìµœì¢… ìš”ì•½\n",
    "                self.execution_log.append(\"ìµœì¢… ìš”ì•½ ìƒì„±\")\n",
    "                state = self._generate_final_summary(state)\n",
    "            else:\n",
    "                self.execution_log.append(\"ê¸°ë³¸ ë¶„ì„ ê²½ë¡œ ì„ íƒ\")\n",
    "                state = self._generate_basic_summary(state)\n",
    "            \n",
    "            # ê²°ê³¼ ë³‘í•©\n",
    "            result = input_json.copy()\n",
    "            result.update({\n",
    "                \"tech_summary\": state.get(\"tech_summary\", \"\"),\n",
    "                \"strengths_and_weaknesses\": state.get(\"strengths_and_weaknesses\", \"\"),\n",
    "                \"differentiation_points\": state.get(\"differentiation_points\", \"\"),\n",
    "                \"technical_risks\": state.get(\"technical_risks\", \"\"),\n",
    "                \"patents_and_papers\": state.get(\"patents_and_papers\", [])\n",
    "            })\n",
    "            \n",
    "            self.execution_log.append(\"ì›Œí¬í”Œë¡œìš° ì™„ë£Œ\")\n",
    "            print(\"ğŸ‰ Agentic ì›Œí¬í”Œë¡œìš° ì™„ë£Œ\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            self.execution_log.append(f\"ì˜¤ë¥˜: {str(e)}\")\n",
    "            return input_json\n",
    "    \n",
    "    def _generate_final_summary(self, state: TechAnalysisState) -> TechAnalysisState:\n",
    "        print(\"ğŸ“ [5ë‹¨ê³„] ìµœì¢… ìš”ì•½ ìƒì„±\")\n",
    "        \n",
    "        # ê°„ì†Œí™”ëœ ìš”ì•½ ìƒì„±\n",
    "        company_name = state.get(\"company_name\", \"\")\n",
    "        core_tech = state.get(\"core_tech\", \"\")\n",
    "        \n",
    "        state.update({\n",
    "            \"tech_summary\": f\"{company_name}ì˜ {core_tech} ê¸°ìˆ ì€ ì›¹ ê²€ìƒ‰ ë° ë‹¤ê°ë„ ë¶„ì„ì„ í†µí•´ ê²€ì¦ëœ í˜ì‹ ì  ê¸°ìˆ ì…ë‹ˆë‹¤. ì‹œì¥ì—ì„œ ì°¨ë³„í™”ëœ ê°€ì¹˜ë¥¼ ì œê³µí•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\",\n",
    "            \"strengths_and_weaknesses\": f\"ê°•ì : {core_tech}ì˜ ê¸°ìˆ ì  ìš°ìˆ˜ì„±ê³¼ íŠ¹í—ˆ ê²½ìŸë ¥. ì•½ì : ì‹œì¥ ì§„ì… ì¥ë²½ê³¼ ê¸°ìˆ  êµ¬í˜„ì˜ ë³µì¡ì„±\",\n",
    "            \"differentiation_points\": f\"{core_tech} ë¶„ì•¼ì—ì„œì˜ ë…íŠ¹í•œ ê¸°ìˆ ì  ì ‘ê·¼ë²•ê³¼ ì›¹ ê²€ìƒ‰ì„ í†µí•´ í™•ì¸ëœ ì‹œì¥ ì°¨ë³„í™” ìš”ì†Œ\",\n",
    "            \"technical_risks\": \"ê¸°ìˆ  êµ¬í˜„ì˜ ë‚œì´ë„, í™•ì¥ì„± ë¬¸ì œ, ì‹œì¥ ìˆ˜ìš©ì„± ë° ê·œì œ ë¦¬ìŠ¤í¬ ì¡´ì¬\",\n",
    "            \"patents_and_papers\": [\n",
    "                {\"type\": \"patent\", \"description\": f\"{core_tech} ê´€ë ¨ í•µì‹¬ íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤\"},\n",
    "                {\"type\": \"research\", \"description\": \"ì›¹ ê²€ìƒ‰ì„ í†µí•´ í™•ì¸ëœ ê¸°ìˆ  ì—°êµ¬ ì„±ê³¼\"}\n",
    "            ],\n",
    "            \"analysis_complete\": True\n",
    "        })\n",
    "        \n",
    "        print(\"  âœ… ìµœì¢… ìš”ì•½ ì™„ë£Œ\")\n",
    "        return state\n",
    "    \n",
    "    def _generate_basic_summary(self, state: TechAnalysisState) -> TechAnalysisState:\n",
    "        print(\"ğŸ“ ê¸°ë³¸ ìš”ì•½ ìƒì„±\")\n",
    "        \n",
    "        state.update({\n",
    "            \"tech_summary\": f\"{state.get('company_name', '')}ì˜ {state.get('core_tech', '')} - ì¶”ê°€ ê²€ì¦ í•„ìš”\",\n",
    "            \"strengths_and_weaknesses\": \"ì œí•œëœ ì •ë³´ë¡œ ì¸í•œ ê¸°ë³¸ ë¶„ì„\",\n",
    "            \"differentiation_points\": \"ì°¨ë³„ì  ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´ í•„ìš”\",\n",
    "            \"technical_risks\": \"ê¸°ìˆ  ê²€ì¦ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ë†’ì€ ë¶ˆí™•ì‹¤ì„±\",\n",
    "            \"patents_and_papers\": [],\n",
    "            \"analysis_complete\": False\n",
    "        })\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def get_execution_log(self):\n",
    "        return self.execution_log\n",
    "\n",
    "print(\"âœ… ë©”ì¸ ì—ì´ì „íŠ¸ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agentic ì›Œí¬í”Œë¡œìš° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_agentic_workflow():\n",
    "    \"\"\"Agentic ì›Œí¬í”Œë¡œìš° ì‹œê°í™”\"\"\"\n",
    "    \n",
    "    # í”Œë¡œìš°ì°¨íŠ¸ ìƒì„±\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # ë…¸ë“œ ì •ì˜\n",
    "    nodes = {\n",
    "        'start': {'pos': (1, 5), 'text': 'ì‹œì‘\\n(ì •ì œëœ ë°ì´í„°)', 'color': 'lightgreen'},\n",
    "        'validate': {'pos': (3, 5), 'text': 'ê¸°ìˆ  ì‹¤ì¡´ì„± ê²€ì¦\\n(ì›¹ê²€ìƒ‰ í¬í•¨)', 'color': 'lightblue'},\n",
    "        'decision': {'pos': (5, 5), 'text': 'ê¸°ìˆ  ì¡´ì¬?', 'color': 'yellow'},\n",
    "        'analyze': {'pos': (7, 6), 'text': 'í•µì‹¬ ê¸°ìˆ  ë¶„ì„\\n(ì›¹ê²€ìƒ‰ ë³´ê°•)', 'color': 'lightcoral'},\n",
    "        'ip_check': {'pos': (9, 6), 'text': 'IP ê²€ì¦\\n(ì›¹ê²€ìƒ‰ êµì°¨ê²€ì¦)', 'color': 'lightyellow'},\n",
    "        'compete': {'pos': (11, 6), 'text': 'ê²½ìŸ ë¶„ì„\\n(ì›¹ê²€ìƒ‰ ê¸°ë°˜)', 'color': 'lightpink'},\n",
    "        'summary': {'pos': (13, 6), 'text': 'ìµœì¢… ìš”ì•½ ìƒì„±', 'color': 'lightgray'},\n",
    "        'basic': {'pos': (7, 4), 'text': 'ê¸°ë³¸ ìš”ì•½ ìƒì„±', 'color': 'lightgray'},\n",
    "        'end': {'pos': (15, 5), 'text': 'ì™„ë£Œ\\n(JSON ì—…ë°ì´íŠ¸)', 'color': 'lightgreen'}\n",
    "    }\n",
    "    \n",
    "    # ë…¸ë“œ ê·¸ë¦¬ê¸°\n",
    "    for node_id, node_info in nodes.items():\n",
    "        x, y = node_info['pos']\n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            x0=x-0.8, y0=y-0.4, x1=x+0.8, y1=y+0.4,\n",
    "            fillcolor=node_info['color'],\n",
    "            line=dict(color=\"black\", width=2)\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=x, y=y,\n",
    "            text=node_info['text'],\n",
    "            showarrow=False,\n",
    "            font=dict(size=10, color=\"black\"),\n",
    "            align=\"center\"\n",
    "        )\n",
    "    \n",
    "    # í™”ì‚´í‘œ ê·¸ë¦¬ê¸°\n",
    "    arrows = [\n",
    "        ('start', 'validate'),\n",
    "        ('validate', 'decision'),\n",
    "        ('decision', 'analyze'),\n",
    "        ('decision', 'basic'),\n",
    "        ('analyze', 'ip_check'),\n",
    "        ('ip_check', 'compete'),\n",
    "        ('compete', 'summary'),\n",
    "        ('summary', 'end'),\n",
    "        ('basic', 'end')\n",
    "    ]\n",
    "    \n",
    "    for start_node, end_node in arrows:\n",
    "        start_pos = nodes[start_node]['pos']\n",
    "        end_pos = nodes[end_node]['pos']\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            x=end_pos[0], y=end_pos[1],\n",
    "            ax=start_pos[0], ay=start_pos[1],\n",
    "            xref=\"x\", yref=\"y\",\n",
    "            axref=\"x\", ayref=\"y\",\n",
    "            arrowhead=2,\n",
    "            arrowsize=1,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor=\"gray\"\n",
    "        )\n",
    "    \n",
    "    # ì¡°ê±´ë¶€ ë¶„ê¸° ë¼ë²¨\n",
    "    fig.add_annotation(\n",
    "        x=6, y=5.7,\n",
    "        text=\"YES\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color=\"green\", family=\"Arial Black\")\n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=6, y=4.3,\n",
    "        text=\"NO\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color=\"red\", family=\"Arial Black\")\n",
    "    )\n",
    "    \n",
    "    # ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': \"ğŸ¤– Agentic ê¸°ìˆ  ìš”ì•½ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°\",\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 20}\n",
    "        },\n",
    "        xaxis=dict(range=[0, 16], showgrid=False, showticklabels=False),\n",
    "        yaxis=dict(range=[3, 7], showgrid=False, showticklabels=False),\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì‹œê°í™” ì‹¤í–‰\n",
    "workflow_fig = visualize_agentic_workflow()\n",
    "workflow_fig.show()\n",
    "\n",
    "print(\"âœ… Agentic ì›Œí¬í”Œë¡œìš° ì‹œê°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "test_companies = [\n",
    "    {\n",
    "        \"owner\": \"ì˜ë£ŒAI ì „ë¬¸ì˜ ì¶œì‹ , ì‹¤í–‰ë ¥ ìš°ìˆ˜\",\n",
    "        \"core_tech\": \"ê·¼ê³¨ê²©ê³„ íŠ¹í™” AI ìì„¸ì¶”ì • ëª¨ë¸\",\n",
    "        \"pros\": \"ê¸€ë¡œë²Œ ì¸ì¬ ì±„ìš©, ì œí’ˆ íŒŒì´í”„ë¼ì¸ ë‹¤ìˆ˜\",\n",
    "        \"patents\": \"17ê°œ íŠ¹í—ˆ ë³´ìœ \",\n",
    "        \"investments\": \"2021~2023 íˆ¬ììœ ì¹˜, ì£¼ìš” íˆ¬ìì LG, ì‚¼ì„±\",\n",
    "        \"company_name\": \"EverEx\"\n",
    "    },\n",
    "    {\n",
    "        \"owner\": \"ì¥ë¬¸ì„ ëŒ€í‘œì´ì‚¬, ì—°ì„¸ëŒ€í•™êµ ìƒí™”í•™ê³¼, ì„œìš¸ëŒ€í•™êµ ìƒëª…ê³¼í•™ë¶€ ë°•ì‚¬\",\n",
    "        \"core_tech\": \"QG3030 í˜ì‹  í•©ì„± ì‹ ì•½ ê°œë°œ, AI ê¸°ë°˜ íŠ¹ì • íƒ€ê²Ÿ ìŠ¤í¬ë¦¬ë‹\",\n",
    "        \"pros\": \"ì¤‘ê°„ì—½ ì¤„ê¸°ì„¸í¬ ë¶„í™” ê¸°ìˆ , ë¹…ë°ì´í„° ë° AI í™œìš©\",\n",
    "        \"patents\": \"êµ­ë‚´ ë“±ë¡ 16ê±´, êµ­ì œ ë“±ë¡ 3ê±´, êµ­ì œ ì¶œì› 3ê±´\",\n",
    "        \"investments\": \"Series A 30ì–µì›, Bridge B 33ì–µì›\",\n",
    "        \"company_name\": \"Qgenetics\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ğŸ“‹ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "for i, company in enumerate(test_companies, 1):\n",
    "    print(f\"{i}. {company['company_name']}: {company['core_tech'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Agentic ì—ì´ì „íŠ¸ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "agent = TechSummaryAgent()\n",
    "\n",
    "print(\"ğŸ¤– Agentic TechSummaryAgent ìƒì„± ì™„ë£Œ\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ íšŒì‚¬ ë¶„ì„\n",
    "print(\"ğŸš€ ì²« ë²ˆì§¸ íšŒì‚¬ ë¶„ì„ ì‹œì‘\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result1 = agent.run(test_companies[0])\n",
    "\n",
    "print(\"\\nğŸ“Š ë¶„ì„ ê²°ê³¼:\")\n",
    "print(\"-\"*40)\n",
    "print(f\"íšŒì‚¬ëª…: {result1.get('company_name', 'N/A')}\")\n",
    "print(f\"ê¸°ìˆ  ìš”ì•½: {result1.get('tech_summary', 'N/A')[:100]}...\")\n",
    "print(f\"ì°¨ë³„ì : {result1.get('differentiation_points', 'N/A')[:100]}...\")\n",
    "print(f\"íŠ¹í—ˆ/ë…¼ë¬¸ ìˆ˜: {len(result1.get('patents_and_papers', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì‹¤í–‰ ë¡œê·¸ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í–‰ ë¡œê·¸ ì‹œê°í™”\n",
    "execution_log = agent.get_execution_log()\n",
    "\n",
    "print(\"ğŸ“ˆ ì‹¤í–‰ ë¡œê·¸:\")\n",
    "print(\"-\"*30)\n",
    "for i, log_entry in enumerate(execution_log, 1):\n",
    "    print(f\"{i:2d}. {log_entry}\")\n",
    "\n",
    "# ì‹¤í–‰ ë‹¨ê³„ ì‹œê°í™”\n",
    "fig_log = go.Figure()\n",
    "\n",
    "fig_log.add_trace(go.Scatter(\n",
    "    x=list(range(1, len(execution_log) + 1)),\n",
    "    y=[1] * len(execution_log),\n",
    "    mode='markers+text',\n",
    "    text=[f\"Step {i}\" for i in range(1, len(execution_log) + 1)],\n",
    "    textposition=\"top center\",\n",
    "    marker=dict(size=15, color='lightblue'),\n",
    "    name=\"ì‹¤í–‰ ë‹¨ê³„\"\n",
    "))\n",
    "\n",
    "# ë‹¨ê³„ë³„ ì„¤ëª… ì¶”ê°€\n",
    "for i, log_entry in enumerate(execution_log, 1):\n",
    "    fig_log.add_annotation(\n",
    "        x=i, y=0.8,\n",
    "        text=log_entry[:30] + \"...\" if len(log_entry) > 30 else log_entry,\n",
    "        showarrow=False,\n",
    "        font=dict(size=8),\n",
    "        textangle=-45\n",
    "    )\n",
    "\n",
    "fig_log.update_layout(\n",
    "    title=\"ğŸ”„ Agentic ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë¡œê·¸\",\n",
    "    xaxis_title=\"ì‹¤í–‰ ë‹¨ê³„\",\n",
    "    yaxis=dict(range=[0.5, 1.5], showticklabels=False),\n",
    "    height=400,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig_log.show()\n",
    "\n",
    "print(\"âœ… ì‹¤í–‰ ë¡œê·¸ ì‹œê°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ê²°ê³¼ ìƒì„¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ìƒì„¸ ì¶œë ¥\n",
    "print(\"ğŸ“„ ìƒì„¸ ë¶„ì„ ê²°ê³¼\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ¯ ê¸°ìˆ  ìš”ì•½:\")\n",
    "print(\"-\" * 40)\n",
    "print(result1.get('tech_summary', 'N/A'))\n",
    "\n",
    "print(\"\\nğŸ’ª ê°•ì  ë° ì•½ì :\")\n",
    "print(\"-\" * 40)\n",
    "print(result1.get('strengths_and_weaknesses', 'N/A'))\n",
    "\n",
    "print(\"\\nğŸ† ì°¨ë³„í™” í¬ì¸íŠ¸:\")\n",
    "print(\"-\" * 40)\n",
    "print(result1.get('differentiation_points', 'N/A'))\n",
    "\n",
    "print(\"\\nâš ï¸ ê¸°ìˆ  ë¦¬ìŠ¤í¬:\")\n",
    "print(\"-\" * 40)\n",
    "print(result1.get('technical_risks', 'N/A'))\n",
    "\n",
    "print(\"\\nğŸ“‹ íŠ¹í—ˆ ë° ë…¼ë¬¸:\")\n",
    "print(\"-\" * 40)\n",
    "patents_papers = result1.get('patents_and_papers', [])\n",
    "if patents_papers:\n",
    "    for i, item in enumerate(patents_papers, 1):\n",
    "        print(f\"{i}. [{item.get('type', 'unknown')}] {item.get('description', 'N/A')}\")\n",
    "else:\n",
    "    print(\"íŠ¹í—ˆ/ë…¼ë¬¸ ì •ë³´ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. JSON ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ê²°ê³¼ JSON ì¶œë ¥\n",
    "print(\"\\nğŸ“„ ì „ì²´ ê²°ê³¼ (JSON):\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(result1, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ì„±ëŠ¥ ë° í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ì„ í†µê³„\n",
    "print(\"\\nğŸ“ˆ ë¶„ì„ í†µê³„:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"ë¶„ì„ ì™„ë£Œ ì—¬ë¶€: {result1.get('analysis_complete', False)}\")\n",
    "print(f\"ì‹¤í–‰ ë‹¨ê³„ ìˆ˜: {len(execution_log)}\")\n",
    "print(f\"íŠ¹í—ˆ/ë…¼ë¬¸ í•­ëª© ìˆ˜: {len(result1.get('patents_and_papers', []))}\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„ì„\n",
    "text_fields = ['tech_summary', 'strengths_and_weaknesses', 'differentiation_points', 'technical_risks']\n",
    "text_lengths = {}\n",
    "\n",
    "print(\"\\nğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„ì„:\")\n",
    "print(\"-\" * 30)\n",
    "for field in text_fields:\n",
    "    text = result1.get(field, '')\n",
    "    length = len(text)\n",
    "    text_lengths[field] = length\n",
    "    print(f\"{field}: {length}ì\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ê¸¸ì´ ì°¨íŠ¸\n",
    "fig_stats = px.bar(\n",
    "    x=list(text_lengths.keys()),\n",
    "    y=list(text_lengths.values()),\n",
    "    title=\"ğŸ“Š ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸ ê¸¸ì´\",\n",
    "    labels={'x': 'ë¶„ì„ í•­ëª©', 'y': 'ê¸€ì ìˆ˜'}\n",
    ")\n",
    "\n",
    "fig_stats.update_layout(height=400)\n",
    "fig_stats.show()\n",
    "\n",
    "print(\"\\nâœ… Agentic ê¸°ìˆ  ìš”ì•½ ì—ì´ì „íŠ¸ ì‹¤ìŠµ ì™„ë£Œ!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}